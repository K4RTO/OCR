import os
import re
import sys
import threading
import time
import zipfile
import io
from pathlib import Path
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import gradio as gr
import pandas as pd
from datetime import datetime
import shutil
import subprocess
from apscheduler.schedulers.background import BackgroundScheduler

# --- Path Setup ---
# å§‹ç»ˆä½¿ç”¨ç›¸å¯¹äºè„šæœ¬æ–‡ä»¶çš„è·¯å¾„ï¼Œæ— è®ºæ˜¯å¼€å‘ç¯å¢ƒè¿˜æ˜¯æ‰“åŒ…ç¯å¢ƒ
if getattr(sys, 'frozen', False):
    # PyInstaller æ‰“åŒ…åçš„ç¯å¢ƒ
    ROOT_DIR = Path(sys.executable).parent
    SRC_DIR = Path(sys._MEIPASS) / 'src'
    APP_DIR = SRC_DIR / 'app'
else:
    # å¼€å‘ç¯å¢ƒï¼šapp.py åœ¨ src/app/ ç›®å½•ä¸‹
    APP_DIR = Path(__file__).resolve().parent
    SRC_DIR = APP_DIR.parent
    ROOT_DIR = SRC_DIR.parent

sys.path.append(str(APP_DIR))

try:
    from mineru.utils.pdf_image_tools import load_images_from_pdf
    from mineru.utils.enum_class import ImageType
except ImportError as e:
    print(f"Error: Failed to import MinerU modules. Current sys.path: {sys.path}")
    print(f"Details: {e}")
    sys.exit(1)

# --- Path Configurations ---
CROP_BOX = (0, 300, 800, 500)
SHIPPING_ID_PATTERN = re.compile(r"å‘è´§å•(?:å·)?\s*[:ï¼š]\s*([A-Za-z0-9]+)")
INPUT_DIR = ROOT_DIR / "input"
OUTPUT_DIR = ROOT_DIR / "output"
DOWNLOADS_DIR = ROOT_DIR / "downloads"
DEBUG_DIR = ROOT_DIR / "debug"
OCR_IMAGES_DIR = DEBUG_DIR / "ocr_annotated"
SHUTDOWN_SENTINEL = ROOT_DIR / ".mineru_shutdown"
OUTPUT_FILE_COLUMNS = ["é€‰æ‹©", "åŸå§‹æ–‡ä»¶å", "é‡å‘½ååæ–‡ä»¶å", "å¤§å°(KB)", "ä¿®æ”¹æ—¶é—´", "å®Œæ•´è·¯å¾„"]

# Global OCR model to load only once
OCR_MODEL = None

# å…¨å±€å­—å…¸ï¼šå­˜å‚¨æ–‡ä»¶ååˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
FILE_PATH_MAP = {}


def clean_hidden_files(directory):
    """åˆ é™¤ç›®å½•ä¸­çš„ .DS_Store ç­‰éšè—åƒåœ¾æ–‡ä»¶"""
    dir_path = Path(directory)
    if not dir_path.exists():
        return

    for ds_store in dir_path.rglob(".DS_Store"):
        try:
            ds_store.unlink()
        except Exception as e:
            print(f"åˆ é™¤éšè—æ–‡ä»¶å¤±è´¥: {ds_store} ({e})")


def clean_empty_subdirs(directory):
    """é€’å½’åˆ é™¤ç›®å½•ä¸‹çš„ç©ºæ–‡ä»¶å¤¹ï¼Œä¿ç•™æ ¹ç›®å½•"""
    dir_path = Path(directory)
    if not dir_path.exists():
        return

    for child in dir_path.iterdir():
        if child.is_dir():
            clean_empty_subdirs(child)
            try:
                if not any(child.iterdir()):
                    child.rmdir()
            except Exception as e:
                print(f"åˆ é™¤ç©ºæ–‡ä»¶å¤¹å¤±è´¥: {child} ({e})")


def normalize_file_manager_df(df):
    """ç¡®ä¿æ–‡ä»¶ç®¡ç†å™¨è¡¨æ ¼æ•°æ®ä¸ºDataFrame"""
    if df is None:
        return None

    if isinstance(df, pd.DataFrame):
        return df

    try:
        if isinstance(df, dict):
            return pd.DataFrame(df)
        return pd.DataFrame(df, columns=OUTPUT_FILE_COLUMNS)
    except Exception as e:
        print(f"è½¬æ¢æ–‡ä»¶è¡¨æ ¼å¤±è´¥: {e}")
        return None

def coerce_selection_column(df):
    """å°†â€œé€‰æ‹©â€åˆ—å¼ºåˆ¶è½¬æ¢ä¸ºå¸ƒå°”ç±»å‹ï¼Œå…¼å®¹å…¨é€‰å‹¾é€‰äº§ç”Ÿçš„å­—ç¬¦ä¸² true çŠ¶æ€"""
    if df is None or "é€‰æ‹©" not in df.columns:
        return df

    def to_bool(val):
        if isinstance(val, bool):
            return val
        if isinstance(val, (int, float)):
            return val != 0
        if isinstance(val, str):
            return val.strip().lower() in {"true", "1", "yes", "y", "on", "checked"}
        return False

    df = df.copy()
    df["é€‰æ‹©"] = df["é€‰æ‹©"].apply(to_bool)
    return df


def get_ocr_model_lazy():
    """Initializes and returns the OCR model, loading it only once."""
    global OCR_MODEL
    if OCR_MODEL is None:
        print("=" * 60)
        print("æ­£åœ¨åŠ è½½ OCR æ¨¡å‹...")
        print("=" * 60)
        try:
            from mineru.model.ocr.pytorch_paddle import PytorchPaddleOCR

            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„å®šä½æ¨¡å‹æ–‡ä»¶
            local_models_root = APP_DIR / "local_models"

            det_model = "models/OCR/paddleocr_torch/ch_PP-OCRv5_det_infer.pth"
            rec_model = "models/OCR/paddleocr_torch/ch_PP-OCRv4_rec_server_doc_infer.pth"
            dict_path = APP_DIR / "mineru" / "model" / "utils" / "pytorchocr" / "utils" / "resources" / "dict" / "ppocrv4_doc_dict.txt"
            det_model_path = local_models_root / det_model
            rec_model_path = local_models_root / rec_model

            # è°ƒè¯•è¾“å‡ºï¼Œå¸®åŠ©æ’æŸ¥è·¯å¾„é—®é¢˜
            print(f"[è·¯å¾„] APP_DIR: {APP_DIR}")
            print(f"[è·¯å¾„] æ£€æµ‹æ¨¡å‹: {det_model_path}")
            print(f"[è·¯å¾„] è¯†åˆ«æ¨¡å‹: {rec_model_path}")
            print(f"[è·¯å¾„] å­—å…¸æ–‡ä»¶: {dict_path}")

            # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
            det_exists = det_model_path.exists()
            rec_exists = rec_model_path.exists()
            dict_exists = dict_path.exists()

            print(f"[éªŒè¯] æ£€æµ‹æ¨¡å‹: {'âœ“' if det_exists else 'âœ—'}")
            print(f"[éªŒè¯] è¯†åˆ«æ¨¡å‹: {'âœ“' if rec_exists else 'âœ—'}")
            print(f"[éªŒè¯] å­—å…¸æ–‡ä»¶: {'âœ“' if dict_exists else 'âœ—'}")

            if not all([det_exists, rec_exists, dict_exists]):
                missing = []
                if not det_exists:
                    missing.append(f"  - æ£€æµ‹æ¨¡å‹: {det_model_path}")
                if not rec_exists:
                    missing.append(f"  - è¯†åˆ«æ¨¡å‹: {rec_model_path}")
                if not dict_exists:
                    missing.append(f"  - å­—å…¸æ–‡ä»¶: {dict_path}")
                error_msg = "æ‰¾ä¸åˆ°ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶:\n" + "\n".join(missing)
                print(f"\nâœ— é”™è¯¯: {error_msg}")
                raise FileNotFoundError(error_msg)

            print("\næ­£åœ¨åˆå§‹åŒ– OCR å¼•æ“ï¼ˆéœ€è¦ 5-10 ç§’ï¼‰...")
            OCR_MODEL = PytorchPaddleOCR(
                lang='ch',
                det_model_path=str(det_model_path),
                rec_model_path=str(rec_model_path),
                rec_char_dict_path=str(dict_path)
            )
            print("âœ“ OCR æ¨¡å‹åŠ è½½å®Œæˆï¼")
            print("=" * 60)
        except Exception as e:
            print(f"\nâœ— é”™è¯¯: æ— æ³•ä»æœ¬åœ°æ–‡ä»¶åˆå§‹åŒ–OCRæ¨¡å‹ã€‚")
            print(f"è¯¦ç»†ä¿¡æ¯: {e}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯ Windows VC++ ç¼ºå¤±çš„é—®é¢˜
            error_msg = str(e)
            if "WinError 126" in error_msg or "c10.dll" in error_msg or "torch" in error_msg:
                print("\n" + "=" * 60)
                print("âš  æ£€æµ‹åˆ° Windows DLL åŠ è½½é”™è¯¯")
                print("=" * 60)
                print("\nè¿™é€šå¸¸æ˜¯å› ä¸ºç¼ºå°‘ Microsoft Visual C++ Redistributable")
                print("\nè§£å†³æ–¹æ¡ˆ:")
                print("  1. ä¸‹è½½å¹¶å®‰è£… VC++ Redistributable:")
                print("     https://aka.ms/vs/17/release/vc_redist.x64.exe")
                print("\n  2. æˆ–è€…é‡æ–°è¿è¡Œ setup.batï¼Œé€‰æ‹©è‡ªåŠ¨å®‰è£…")
                print("\n  3. å®‰è£…å®Œæˆåï¼Œé‡å¯æ­¤åº”ç”¨")
                print("=" * 60)
            else:
                import traceback
                traceback.print_exc()
                print("=" * 60)

            OCR_MODEL = None
    return OCR_MODEL

def draw_ocr_boxes(image, ocr_results, highlight_text=None):
    """
    åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶ OCR è¯†åˆ«æ¡†ï¼Œå¹¶ç”¨çº¢è‰²é«˜äº®ç‰¹å®šæ–‡æœ¬
    """
    draw_image = image.copy()
    draw = ImageDraw.Draw(draw_image)

    # Linuxå­—ä½“åŠ è½½
    font = None
    font_candidates = [
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
        "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
        "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
    ]

    # å°è¯•åŠ è½½å­—ä½“
    for font_path in font_candidates:
        try:
            font = ImageFont.truetype(font_path, 20)
            break
        except:
            continue

    # å¦‚æœæ‰€æœ‰å­—ä½“éƒ½åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“
    if font is None:
        font = ImageFont.load_default()

    if ocr_results and ocr_results[0]:
        for box_info, rec_data in ocr_results[0]:
            box = box_info
            text, confidence = rec_data

            # åˆ¤æ–­æ˜¯å¦æ˜¯éœ€è¦é«˜äº®çš„æ–‡æœ¬
            is_highlight = highlight_text and highlight_text in text
            color = (255, 0, 0) if is_highlight else (0, 255, 0)  # çº¢è‰²é«˜äº®ï¼Œç»¿è‰²æ™®é€š
            width = 3 if is_highlight else 2

            # ç»˜åˆ¶è¾¹æ¡†
            points = [(int(p[0]), int(p[1])) for p in box]
            draw.polygon(points, outline=color, width=width)

            # ç»˜åˆ¶æ–‡æœ¬
            draw.text((int(box[0][0]), int(box[0][1]) - 25), text, fill=color, font=font)

    return draw_image

def extract_shipping_number_from_pdf(pdf_path: str, ocr_model, crop_box: tuple):
    """
    ä»PDFæå–å‘è´§å•å·ï¼Œå¹¶è¿”å›å¸¦æ ‡æ³¨çš„å›¾ç‰‡
    è¿”å›: (shipping_id, status_msg, annotated_image_path)
    """
    if ocr_model is None:
        return "Error", "OCRæ¨¡å‹æœªåŠ è½½", None

    try:
        with open(pdf_path, 'rb') as f:
            pdf_bytes = f.read()

        images_tuple = load_images_from_pdf(pdf_bytes, dpi=200, start_page_id=0, end_page_id=0, image_type=ImageType.PIL)
        images_list = images_tuple[0]

        if not images_list:
            return "Not Found", "æ— æ³•ä»PDFä¸­è¯»å–å›¾åƒ", None

        first_page_image = images_list[0]['img_pil']
        cropped_image = first_page_image.crop(crop_box)

        # OCRè¯†åˆ«
        cropped_np_image = np.array(cropped_image)
        ocr_raw_results = ocr_model.ocr(cropped_np_image)

        full_text = ""
        if ocr_raw_results and ocr_raw_results[0]:
            for _, rec_data in ocr_raw_results[0]:
                text, _ = rec_data
                full_text += text + " "

        full_text = full_text.strip()

        # æŸ¥æ‰¾å‘è´§å•å·
        match = SHIPPING_ID_PATTERN.search(full_text)

        # Fallback to full page OCR if not found in crop box
        use_full_page = False
        if not match:
            print(f"åœ¨ CROP_BOX åŒºåŸŸæœªæ‰¾åˆ°å•å·ï¼Œæ­£åœ¨å°è¯•å…¨å±€é¡µé¢è¯†åˆ«...")
            full_page_np_image = np.array(first_page_image)
            ocr_full_page_results = ocr_model.ocr(full_page_np_image)
            use_full_page = True

            full_page_text = ""
            if ocr_full_page_results and ocr_full_page_results[0]:
                for _, rec_data in ocr_full_page_results[0]:
                    text, _ = rec_data
                    full_page_text += text + " "

            full_page_text = full_page_text.strip()
            match = SHIPPING_ID_PATTERN.search(full_page_text)
            ocr_raw_results = ocr_full_page_results

        shipping_id = "Not Found"
        if match:
            shipping_id = match.group(1)

        # ç»˜åˆ¶æ ‡æ³¨å›¾ç‰‡
        OCR_IMAGES_DIR.mkdir(parents=True, exist_ok=True)

        # é€‰æ‹©åˆé€‚çš„å›¾ç‰‡è¿›è¡Œæ ‡æ³¨
        if use_full_page:
            annotated_image = draw_ocr_boxes(first_page_image, ocr_raw_results, shipping_id if shipping_id != "Not Found" else None)
        else:
            annotated_image = draw_ocr_boxes(cropped_image, ocr_raw_results, shipping_id if shipping_id != "Not Found" else None)

        # ä¿å­˜æ ‡æ³¨å›¾ç‰‡
        image_filename = f"{Path(pdf_path).stem}_ocr.png"
        image_path = OCR_IMAGES_DIR / image_filename
        annotated_image.save(image_path)

        # åˆ›å»ºç¼©ç•¥å›¾
        thumbnail = annotated_image.copy()
        thumbnail.thumbnail((300, 300))
        thumbnail_path = OCR_IMAGES_DIR / f"{Path(pdf_path).stem}_thumb.png"
        thumbnail.save(thumbnail_path)

        status = f"æˆåŠŸ: {shipping_id}" if shipping_id != "Not Found" else f"æœªæ‰¾åˆ°å•å·ã€‚OCRå†…å®¹: '{full_text[:50]}...'"

        return shipping_id, status, str(thumbnail_path)

    except Exception as e:
        return "Error", f"å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", None

def process_uploads_and_extract(files):
    """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶å¹¶æå–å•å·"""
    global FILE_PATH_MAP
    clean_hidden_files(INPUT_DIR)
    clean_hidden_files(OUTPUT_DIR)

    if not files:
        return pd.DataFrame(columns=["åŸå§‹æ–‡ä»¶å", "æå–çš„å•å·", "æå–å›¾åƒ"]), "", "è¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚"

    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    input_batch_dir = INPUT_DIR / timestamp_str
    input_batch_dir.mkdir(parents=True, exist_ok=True)

    processed_files = []
    FILE_PATH_MAP.clear()  # æ¸…ç©ºä¹‹å‰çš„æ˜ å°„

    for file_obj in files:
        temp_path = file_obj.name
        original_filename = Path(temp_path).name
        dest_path = input_batch_dir / original_filename
        shutil.copy(temp_path, dest_path)
        processed_files.append(str(dest_path))
        FILE_PATH_MAP[original_filename] = str(dest_path)  # å­˜å‚¨æ˜ å°„

    # è·å– OCR æ¨¡å‹ï¼ˆå·²åœ¨å¯åŠ¨æ—¶é¢„åŠ è½½ï¼‰
    ocr_model = get_ocr_model_lazy()
    if ocr_model is None:
        return pd.DataFrame(columns=["åŸå§‹æ–‡ä»¶å", "æå–çš„å•å·", "æå–å›¾åƒ"]), "", "é”™è¯¯ï¼šOCR æ¨¡å‹æœªåŠ è½½ï¼Œè¯·é‡å¯åº”ç”¨ã€‚"

    results = []
    for pdf_path in processed_files:
        print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {Path(pdf_path).name}")
        shipping_id, status, thumbnail_path = extract_shipping_number_from_pdf(pdf_path, ocr_model, CROP_BOX)

        results.append([
            Path(pdf_path).name,
            shipping_id,
            thumbnail_path if thumbnail_path else ""
        ])

    df = pd.DataFrame(results, columns=["åŸå§‹æ–‡ä»¶å", "æå–çš„å•å·", "æå–å›¾åƒ"])
    return df, "", f"æ–‡ä»¶å·²å­˜å…¥ {input_batch_dir} å¹¶å®Œæˆæå–ã€‚"

def view_ocr_image(df, evt: gr.SelectData):
    """æŸ¥çœ‹é€‰ä¸­è¡Œçš„OCRæ ‡æ³¨å›¾ç‰‡"""
    if df is None or df.empty:
        return None

    row_index = evt.index[0]
    thumbnail_path = df.iloc[row_index]["æå–å›¾åƒ"]

    # ä»ç¼©ç•¥å›¾è·¯å¾„è·å–å®Œæ•´å›¾åƒè·¯å¾„
    full_image_path = thumbnail_path.replace("_thumb.png", "_ocr.png") if thumbnail_path else None

    if full_image_path and Path(full_image_path).exists():
        return full_image_path
    return None

def rename_files_and_organize(df):
    """é‡å‘½åæ–‡ä»¶å¹¶æ•´ç†åˆ°è¾“å‡ºç›®å½•"""
    global FILE_PATH_MAP

    if df is None or df.empty:
        return "æ²¡æœ‰æ–‡ä»¶éœ€è¦å¤„ç†ã€‚"

    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_batch_dir = OUTPUT_DIR / timestamp_str
    output_batch_dir.mkdir(parents=True, exist_ok=True)

    rename_log = []
    for index, row in df.iterrows():
        original_filename = row["åŸå§‹æ–‡ä»¶å"]
        new_shipping_id = row["æå–çš„å•å·"]

        # ä»å…¨å±€æ˜ å°„è·å–æ–‡ä»¶è·¯å¾„
        source_path_str = FILE_PATH_MAP.get(original_filename)
        if not source_path_str:
            log_msg = f"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ '{original_filename}' çš„è·¯å¾„"
            print(log_msg)
            rename_log.append(log_msg)
            continue

        source_path = Path(source_path_str)
        original_filename = source_path.name

        if not source_path.exists():
            log_msg = f"é”™è¯¯: æ–‡ä»¶ '{original_filename}' ä¸å­˜åœ¨ï¼Œå·²è·³è¿‡ã€‚"
            print(log_msg)
            rename_log.append(log_msg)
            continue

        file_output_dir = output_batch_dir / source_path.stem
        file_output_dir.mkdir(exist_ok=True)

        dest_original_path = file_output_dir / original_filename
        shutil.copy(source_path, dest_original_path)

        if new_shipping_id in ["Not Found", "Error", "", None]:
            log_msg = f"æ–‡ä»¶ '{original_filename}' çš„å•å·æ— æ•ˆ, ä»…å¤åˆ¶æºæ–‡ä»¶ã€‚"
            print(log_msg)
            rename_log.append(log_msg)
            continue

        new_filename = f"{new_shipping_id}.pdf"
        new_path = file_output_dir / new_filename

        try:
            dest_original_path.rename(new_path)
            log_msg = f"æˆåŠŸ: '{original_filename}' -> '{new_filename}'"
            print(log_msg)
            rename_log.append(log_msg)
        except Exception as e:
            log_msg = f"é”™è¯¯: é‡å‘½å '{original_filename}' æ—¶å‘ç”Ÿé”™è¯¯: {e}"
            print(log_msg)
            rename_log.append(log_msg)

    return f"å¤„ç†å®Œæˆï¼Œç»“æœå·²å­˜å…¥ {output_batch_dir}ã€‚\n\n" + "\n".join(rename_log)


def open_directory(directory):
    """åœ¨Linuxç³»ç»Ÿæ–‡ä»¶ç®¡ç†å™¨ä¸­æ‰“å¼€æŒ‡å®šç›®å½•"""
    dir_path = Path(directory)
    dir_path.mkdir(parents=True, exist_ok=True)

    try:
        subprocess.Popen(["xdg-open", str(dir_path)])
        return f"å·²æ‰“å¼€ {dir_path}"
    except Exception as e:
        return f"æ‰“å¼€ç›®å½•å¤±è´¥ (ä»…æœåŠ¡å™¨ç«¯å¯ç”¨): {e}"

def list_output_files():
    """åˆ—å‡ºoutputç›®å½•çš„æ–‡ä»¶,æ˜¾ç¤ºåŸå§‹åå’Œé‡å‘½ååçš„åå­—"""
    dir_path = OUTPUT_DIR
    clean_hidden_files(dir_path)
    if not dir_path.exists():
        return pd.DataFrame(columns=OUTPUT_FILE_COLUMNS)

    files_info = []
    # éå†outputç›®å½•ä¸‹çš„æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶å¤¹
    for batch_dir in sorted(dir_path.iterdir()):
        if not batch_dir.is_dir():
            continue

        # æ¯ä¸ªæ‰¹æ¬¡æ–‡ä»¶å¤¹ä¸‹æœ‰å­æ–‡ä»¶å¤¹,æ–‡ä»¶å¤¹åæ˜¯åŸå§‹æ–‡ä»¶å(å»æ‰.pdfåç¼€)
        for original_dir in sorted(batch_dir.iterdir()):
            if not original_dir.is_dir():
                continue

            original_name = original_dir.name  # åŸå§‹æ–‡ä»¶å(ä¸å«åç¼€)

            # æŸ¥æ‰¾è¯¥ç›®å½•ä¸‹çš„PDFæ–‡ä»¶
            for pdf_file in original_dir.glob("*.pdf"):
                size_kb = pdf_file.stat().st_size / 1024
                mtime = datetime.fromtimestamp(pdf_file.stat().st_mtime).strftime("%Y-%m-%d %H:%M:%S")
                renamed_name = pdf_file.name  # é‡å‘½ååçš„æ–‡ä»¶å

                files_info.append([
                    False,  # é€‰æ‹©
                    f"{original_name}.pdf",  # åŸå§‹æ–‡ä»¶å
                    renamed_name,  # é‡å‘½ååæ–‡ä»¶å
                    f"{size_kb:.2f}",  # å¤§å°
                    mtime,  # ä¿®æ”¹æ—¶é—´
                    str(pdf_file)  # å®Œæ•´è·¯å¾„(éšè—)
                ])

    df = pd.DataFrame(files_info, columns=OUTPUT_FILE_COLUMNS)
    return coerce_selection_column(df)

def delete_selected_files(df):
    """åˆ é™¤é€‰ä¸­çš„æ–‡ä»¶"""
    df = normalize_file_manager_df(df)
    df = coerce_selection_column(df)
    if df is None or df.empty:
        return "æ²¡æœ‰æ–‡ä»¶"

    # è·å–æ‰€æœ‰é€‰ä¸­çš„æ–‡ä»¶
    selected_files = df[df["é€‰æ‹©"] == True]["å®Œæ•´è·¯å¾„"].tolist()

    if not selected_files:
        return "è¯·å…ˆå‹¾é€‰è¦åˆ é™¤çš„æ–‡ä»¶"

    # æ‰§è¡Œåˆ é™¤
    deleted = []
    failed = []
    for file_path_str in selected_files:
        file_path = Path(file_path_str)
        try:
            if file_path.exists():
                file_path.unlink()
                deleted.append(file_path.name)
            else:
                failed.append(f"{file_path.name} (ä¸å­˜åœ¨)")
        except Exception as e:
            failed.append(f"{file_path.name} ({e})")

    result_msg = f"æˆåŠŸåˆ é™¤ {len(deleted)} ä¸ªæ–‡ä»¶"
    if failed:
        result_msg += f"\nå¤±è´¥: {', '.join(failed)}"

    return result_msg


def download_selected_files_as_zip(df, directory):
    """å°†ç”¨æˆ·é€‰ä¸­çš„æ–‡ä»¶æ‰“åŒ…ä¸ºZIPä¾›ä¸‹è½½"""
    df = normalize_file_manager_df(df)
    df = coerce_selection_column(df)

    if df is None or df.empty:
        return None

    # è·å–æ‰€æœ‰é€‰ä¸­çš„æ–‡ä»¶
    selected_files = df[df["é€‰æ‹©"] == True]["å®Œæ•´è·¯å¾„"].tolist()

    if not selected_files:
        return None  # æ²¡æœ‰é€‰ä¸­æ–‡ä»¶

    # åˆ›å»ºä¸€ä¸ªå†…å­˜ä¸­çš„ZIPæ–‡ä»¶
    zip_buffer = io.BytesIO()

    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file_path_str in selected_files:
            file_path = Path(file_path_str)
            if file_path.exists() and file_path.is_file():
                # ä½¿ç”¨ç›¸å¯¹äºdirectoryçš„è·¯å¾„ä½œä¸ºå‹ç¼©åŒ…å†…çš„è·¯å¾„
                dir_path = Path(directory)
                try:
                    arcname = file_path.relative_to(dir_path)
                except ValueError:
                    # å¦‚æœæ–‡ä»¶ä¸åœ¨directoryä¸‹ï¼Œä½¿ç”¨æ–‡ä»¶å
                    arcname = file_path.name
                zipf.write(file_path, arcname)

    zip_buffer.seek(0)

    # ä¿å­˜åˆ°downloadsç›®å½•
    DOWNLOADS_DIR.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    zip_filename = f"{timestamp}.zip"
    zip_path = DOWNLOADS_DIR / zip_filename

    with open(zip_path, 'wb') as f:
        f.write(zip_buffer.read())

    return str(zip_path)


def cleanup_cache_files():
    """æ¸…ç†è°ƒè¯•ä¸ç¼“å­˜ç›®å½•"""
    for cache_dir in [DEBUG_DIR, OCR_IMAGES_DIR]:
        if not cache_dir.exists():
            continue
        for item in cache_dir.iterdir():
            try:
                if item.is_dir():
                    shutil.rmtree(item, ignore_errors=True)
                else:
                    item.unlink()
            except Exception as e:
                print(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {item} ({e})")


def cleanup_input_directory():
    """æ¸…ç†inputç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ (æ¯5åˆ†é’Ÿæ‰§è¡Œ)"""
    print(f"[å®šæ—¶ä»»åŠ¡] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - å¼€å§‹æ¸…ç† input ç›®å½•")
    if INPUT_DIR.exists():
        try:
            for item in INPUT_DIR.iterdir():
                if item.is_file():
                    item.unlink()
                    print(f"  åˆ é™¤æ–‡ä»¶: {item.name}")
                elif item.is_dir():
                    shutil.rmtree(item, ignore_errors=True)
                    print(f"  åˆ é™¤ç›®å½•: {item.name}")
            clean_hidden_files(INPUT_DIR)
            print(f"[å®šæ—¶ä»»åŠ¡] input ç›®å½•æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"[å®šæ—¶ä»»åŠ¡] input ç›®å½•æ¸…ç†å¤±è´¥: {e}")


def cleanup_output_directory():
    """æ¸…ç†outputç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ (æ¯å¤©0ç‚¹æ‰§è¡Œ)"""
    print(f"[å®šæ—¶ä»»åŠ¡] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - å¼€å§‹æ¸…ç† output ç›®å½•")
    if OUTPUT_DIR.exists():
        try:
            for item in OUTPUT_DIR.iterdir():
                if item.is_file():
                    item.unlink()
                    print(f"  åˆ é™¤æ–‡ä»¶: {item.name}")
                elif item.is_dir():
                    shutil.rmtree(item, ignore_errors=True)
                    print(f"  åˆ é™¤ç›®å½•: {item.name}")
            clean_hidden_files(OUTPUT_DIR)
            print(f"[å®šæ—¶ä»»åŠ¡] output ç›®å½•æ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"[å®šæ—¶ä»»åŠ¡] output ç›®å½•æ¸…ç†å¤±è´¥: {e}")


def cleanup_downloads_directory():
    """æ¸…ç†downloadsç›®å½•ä¸­è¶…è¿‡10åˆ†é’Ÿçš„æ–‡ä»¶ (æ¯5åˆ†é’Ÿæ‰§è¡Œ)"""
    print(f"[å®šæ—¶ä»»åŠ¡] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - å¼€å§‹æ¸…ç† downloads ç›®å½•")
    if DOWNLOADS_DIR.exists():
        try:
            current_time = datetime.now()
            cleaned_count = 0
            for item in DOWNLOADS_DIR.iterdir():
                if item.is_file():
                    file_age = current_time - datetime.fromtimestamp(item.stat().st_mtime)
                    if file_age.total_seconds() > 600:  # 10åˆ†é’Ÿ = 600ç§’
                        item.unlink()
                        cleaned_count += 1
                        print(f"  åˆ é™¤æ–‡ä»¶: {item.name} (å·²å­˜åœ¨ {file_age.total_seconds():.0f} ç§’)")
                elif item.is_dir():
                    # ç›®å½•ä¹Ÿæ£€æŸ¥æ—¶é—´
                    dir_age = current_time - datetime.fromtimestamp(item.stat().st_mtime)
                    if dir_age.total_seconds() > 600:
                        shutil.rmtree(item, ignore_errors=True)
                        cleaned_count += 1
                        print(f"  åˆ é™¤ç›®å½•: {item.name}")
            clean_hidden_files(DOWNLOADS_DIR)
            if cleaned_count > 0:
                print(f"[å®šæ—¶ä»»åŠ¡] downloads ç›®å½•æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªæ–‡ä»¶/ç›®å½•")
            else:
                print(f"[å®šæ—¶ä»»åŠ¡] downloads ç›®å½•æ— éœ€æ¸…ç†ï¼ˆæ— è¶…è¿‡10åˆ†é’Ÿçš„æ–‡ä»¶ï¼‰")
        except Exception as e:
            print(f"[å®šæ—¶ä»»åŠ¡] downloads ç›®å½•æ¸…ç†å¤±è´¥: {e}")


def get_next_cleanup_time():
    """è·å–ä¸‹æ¬¡æ¸…ç†æ—¶é—´"""
    now = datetime.now()
    # è®¡ç®—ä¸‹æ¬¡outputæ¸…ç†æ—¶é—´(æ¯å¤©0ç‚¹)
    if now.hour == 0 and now.minute < 5:
        next_cleanup = now.replace(hour=0, minute=0, second=0, microsecond=0)
    else:
        next_cleanup = (now + pd.Timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)

    return next_cleanup.strftime('%Y-%m-%d %H:%M:%S')


# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft(primary_hue="slate").set(
    body_background_fill="*neutral_950",
    body_background_fill_dark="*neutral_950",
    background_fill_primary="*neutral_900",
    background_fill_primary_dark="*neutral_900",
    background_fill_secondary="*neutral_800",
    background_fill_secondary_dark="*neutral_800",
    border_color_primary="*neutral_700",
    border_color_primary_dark="*neutral_700",
), css="""
    .thumbnail-cell img { max-width: 150px; max-height: 150px; object-fit: contain; }
    #pdf-upload button[aria-label="Upload"],
    #pdf-upload button[aria-label="Upload file"] {
        min-width: 150px;
        border-radius: 6px;
        font-weight: 600;
        font-size: 14px;
        padding: 0.4rem 1rem;
        background: var(--button-primary-background-fill, var(--primary-500));
        border: 1px solid var(--button-primary-border-color, var(--primary-500));
        color: var(--button-primary-text-color, #fff);
        box-shadow: 0 2px 6px rgba(0, 0, 0, 0.1);
    }
    #pdf-upload button[aria-label="Upload"]:hover,
    #pdf-upload button[aria-label="Upload file"]:hover {
        filter: brightness(1.05);
    }
    #pdf-upload button[aria-label="Upload"]::after,
    #pdf-upload button[aria-label="Upload file"]::after {
        content: " ä¸Šä¼ æ–‡ä»¶";
        margin-left: 6px;
    }
    /* éšè—DataFrameçš„æ·»åŠ è¡ŒæŒ‰é’® */
    button[title="Add row"], button[aria-label="Add row"] {
        display: none !important;
    }
    /* æç¤ºç”¨æˆ·åªæœ‰å•å·åˆ—å¯ç¼–è¾‘ */
    .dataframe tbody tr td:first-child,
    .dataframe tbody tr td:last-child {
        background-color: rgba(128, 128, 128, 0.1) !important;
        cursor: not-allowed;
    }
    /* ç´«è‰²ä¸»é¢˜æ ·å¼ */
    #loading_status textarea,
    #status_extract textarea,
    #status_rename textarea,
    #file_op_status textarea {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        color: white !important;
        border: none !important;
        font-weight: 500 !important;
    }
    #ocr_viewer {
        border: 2px solid #667eea !important;
        border-radius: 8px !important;
    }
""") as demo:
    gr.Markdown("## OCR - æœåŠ¡å™¨ç‰ˆ")
    gr.Markdown(
        """
        **ä½¿ç”¨è¯´æ˜:**
        1. ä¸Šä¼ PDFæ–‡ä»¶å¹¶ç‚¹å‡» **"å¼€å§‹æå–"**
        2. æŸ¥çœ‹æå–ç»“æœï¼Œç‚¹å‡»è¡¨æ ¼è¡Œå³å¯åœ¨å³ä¾§é¢„è§ˆå¤§å›¾
        3. å¦‚éœ€ä¿®æ”¹å•å·ï¼Œåœ¨è¡¨æ ¼ä¸­ç›´æ¥ç¼–è¾‘åç‚¹å‡» **"ç¡®è®¤å¹¶é‡å‘½å"**
        4. åœ¨æ–‡ä»¶ç®¡ç†å™¨ä¸­å‹¾é€‰éœ€è¦çš„æ–‡ä»¶ï¼Œç‚¹å‡» **"ğŸ“¥ æ‰¹é‡ä¸‹è½½"**
        5. âš ï¸ **é‡è¦**: è¾“å‡ºæ–‡ä»¶æ¯å¤©00:00è‡ªåŠ¨æ¸…ç†ï¼Œä¸‹è½½é“¾æ¥10åˆ†é’Ÿåå¤±æ•ˆï¼Œè¯·åŠæ—¶ä¸‹è½½
        """
    )

    # æ˜¾ç¤ºæ¸…ç†æ—¶é—´ä¿¡æ¯
    cleanup_info = gr.Markdown(value="ğŸ“‹ **æ–‡ä»¶è‡ªåŠ¨æ¸…ç†**: æ¯å¤© 00:00 æ¸…ç† (ä¸‹æ¬¡: " + get_next_cleanup_time() + ")")

    # ä¸Šä¼ å’Œæå–éƒ¨åˆ†
    with gr.Row():
        upload_button = gr.File(
            label="ä¸Šä¼ PDFæ–‡ä»¶",
            file_count="multiple",
            file_types=[".pdf"],
            elem_id="pdf-upload"
        )

    extract_button = gr.Button("å¼€å§‹æå–", variant="primary")
    loading_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", value="", interactive=False, visible=True)
    status_textbox_extract = gr.Textbox(label="æå–çŠ¶æ€", interactive=False)

    # ç»“æœè¡¨æ ¼
    results_df = gr.DataFrame(
        headers=["åŸå§‹æ–‡ä»¶å", "æå–çš„å•å·ï¼ˆç‚¹å‡»ä¸‹æ–¹é‡å‘½åï¼‰", "æå–å›¾åƒ"],
        datatype=["str", "str", "str"],
        interactive=True,
        visible=True,
        wrap=True
    )

    # å›¾ç‰‡æŸ¥çœ‹å™¨
    with gr.Row():
        with gr.Column(scale=2):
            ocr_image_viewer = gr.Image(label="OCRè¯†åˆ«ç»“æœï¼ˆç‚¹å‡»è¡¨æ ¼è¡ŒæŸ¥çœ‹å¤§å›¾ï¼‰", type="filepath")
        with gr.Column(scale=1):
            gr.Markdown("""
            **å›¾ç‰‡è¯´æ˜:**
            - ğŸŸ¢ ç»¿è‰²æ¡†ï¼šæ™®é€šè¯†åˆ«æ–‡æœ¬
            - ğŸ”´ çº¢è‰²æ¡†ï¼šå‘è´§å•å·
            - ç‚¹å‡»è¡¨æ ¼ä»»æ„è¡ŒæŸ¥çœ‹å¯¹åº”å›¾ç‰‡
            """)

    # é‡å‘½åéƒ¨åˆ†
    rename_button = gr.Button("ç¡®è®¤å¹¶é‡å‘½å", variant="stop")
    status_textbox_rename = gr.Textbox(label="é‡å‘½åçŠ¶æ€", lines=5, interactive=False)

    gr.Markdown("---")
    gr.Markdown("### æ–‡ä»¶ç®¡ç†å™¨")

    # æ–‡ä»¶æµè§ˆå™¨
    with gr.Row():
        refresh_output_btn = gr.Button("åˆ·æ–°", size="sm")
        download_output_btn = gr.Button("ğŸ“¥ æ‰¹é‡ä¸‹è½½", size="sm", variant="primary")
        delete_output_btn = gr.Button("åˆ é™¤é€‰ä¸­", variant="stop", size="sm")

    output_files_df = gr.DataFrame(
        headers=["", "åŸå§‹æ–‡ä»¶å", "é‡å‘½ååæ–‡ä»¶å", "å¤§å°(KB)", "ä¿®æ”¹æ—¶é—´"],
        label="å·²å¤„ç†æ–‡ä»¶åˆ—è¡¨",
        datatype=["bool", "str", "str", "str", "str"],
        interactive=True,
        column_widths=["8%", "30%", "30%", "12%", "20%"],
        value=list_output_files()
    )

    file_op_status = gr.Textbox(label="æ“ä½œçŠ¶æ€", interactive=False)

    # ä¸‹è½½æ–‡ä»¶ç»„ä»¶
    download_file = gr.File(label="ä¸‹è½½æ–‡ä»¶", interactive=False)

    # äº‹ä»¶ç»‘å®š
    extract_button.click(
        fn=process_uploads_and_extract,
        inputs=upload_button,
        outputs=[results_df, loading_status, status_textbox_extract]
    )

    results_df.select(
        fn=view_ocr_image,
        inputs=results_df,
        outputs=ocr_image_viewer
    )

    rename_button.click(
        fn=rename_files_and_organize,
        inputs=results_df,
        outputs=status_textbox_rename
    )

    # Outputæ–‡ä»¶æµè§ˆå™¨äº‹ä»¶
    refresh_output_btn.click(
        fn=list_output_files,
        outputs=output_files_df
    )

    # åˆ é™¤æ–‡ä»¶ - Outputç›®å½•
    def handle_delete(df):
        msg = delete_selected_files(df)
        return msg, list_output_files()

    delete_output_btn.click(
        fn=handle_delete,
        inputs=output_files_df,
        outputs=[file_op_status, output_files_df]
    )

    # ä¸‹è½½outputç›®å½•é€‰ä¸­çš„æ–‡ä»¶
    def handle_download(df):
        zip_path = download_selected_files_as_zip(df, OUTPUT_DIR)
        if zip_path is None:
            return None, "âŒ è¯·å…ˆå‹¾é€‰è¦ä¸‹è½½çš„æ–‡ä»¶"
        return zip_path, f"âœ“ å·²æ‰“åŒ… {Path(zip_path).name}ï¼Œç‚¹å‡»ä¸‹æ–¹ä¸‹è½½"

    download_output_btn.click(
        fn=handle_download,
        inputs=output_files_df,
        outputs=[download_file, file_op_status]
    )

    # é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–æ–‡ä»¶åˆ—è¡¨å’Œæ¸…ç†ä¿¡æ¯
    demo.load(
        fn=lambda: (list_output_files(), "ğŸ“‹ **æ–‡ä»¶è‡ªåŠ¨æ¸…ç†**: æ¯å¤© 00:00 æ¸…ç† (ä¸‹æ¬¡: " + get_next_cleanup_time() + ")"),
        outputs=[output_files_df, cleanup_info]
    )

if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("OCR - æœåŠ¡å™¨ç‰ˆå¯åŠ¨ä¸­...")
    print("=" * 60)

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    INPUT_DIR.mkdir(exist_ok=True)
    OUTPUT_DIR.mkdir(exist_ok=True)
    DOWNLOADS_DIR.mkdir(exist_ok=True)
    DEBUG_DIR.mkdir(exist_ok=True)
    OCR_IMAGES_DIR.mkdir(exist_ok=True)
    print("âœ“ ç›®å½•åˆå§‹åŒ–å®Œæˆ")

    # é¢„åŠ è½½ OCR æ¨¡å‹ï¼ˆåœ¨å¯åŠ¨æ—¶å°±åŠ è½½ï¼Œé¿å…é¦–æ¬¡ä½¿ç”¨æ—¶ç­‰å¾…ï¼‰
    print("\næ­£åœ¨é¢„åŠ è½½ OCR æ¨¡å‹...")
    model = get_ocr_model_lazy()
    if model is None:
        print("\nâš  è­¦å‘Š: OCR æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        print("å¯ä»¥ç»§ç»­å¯åŠ¨åº”ç”¨ï¼Œä½† OCR åŠŸèƒ½å°†ä¸å¯ç”¨")
        print("=" * 60)

    # å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡
    print("\næ­£åœ¨å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡...")
    scheduler = BackgroundScheduler()

    # Inputç›®å½•: æ¯5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
    scheduler.add_job(cleanup_input_directory, 'interval', minutes=5, id='cleanup_input')

    # Outputç›®å½•: æ¯å¤©00:00æ¸…ç†
    scheduler.add_job(cleanup_output_directory, 'cron', hour=0, minute=0, id='cleanup_output')

    # Downloadsç›®å½•: æ¯5åˆ†é’Ÿæ¸…ç†è¶…è¿‡10åˆ†é’Ÿçš„æ–‡ä»¶
    scheduler.add_job(cleanup_downloads_directory, 'interval', minutes=5, id='cleanup_downloads')

    scheduler.start()
    print("âœ“ å®šæ—¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")
    print("  - Inputç›®å½•: æ¯5åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡")
    print("  - Outputç›®å½•: æ¯å¤©00:00æ¸…ç†")
    print("  - Downloadsç›®å½•: æ¯5åˆ†é’Ÿæ¸…ç†è¶…è¿‡10åˆ†é’Ÿçš„æ–‡ä»¶")

    # å¯åŠ¨ Gradio åº”ç”¨
    print("\næ­£åœ¨å¯åŠ¨ Web æœåŠ¡...")
    print("=" * 60)

    # æ ¹æ®æ“ä½œç³»ç»Ÿè‡ªåŠ¨é€‚é…
    is_macos = sys.platform.startswith("darwin")
    if is_macos:
        server_name = "127.0.0.1"
        open_browser = True
        print("å¼€å‘æ¨¡å¼ (macOS)")
        print("è®¿é—®åœ°å€: http://127.0.0.1:8143")
    else:
        server_name = "0.0.0.0"
        open_browser = False
        print("æœåŠ¡å™¨æ¨¡å¼ (Linux)")
        print("è®¿é—®åœ°å€: http://0.0.0.0:8143")
        print("å¤–ç½‘è®¿é—®: http://<æœåŠ¡å™¨IP>:8143")

    print("=" * 60)

    try:
        demo.launch(
            server_name=server_name,
            server_port=8143,
            share=False,
            inbrowser=open_browser
        )
    except KeyboardInterrupt:
        print("\næ­£åœ¨å…³é—­...")
        scheduler.shutdown()
        print("å®šæ—¶ä»»åŠ¡å·²åœæ­¢")
